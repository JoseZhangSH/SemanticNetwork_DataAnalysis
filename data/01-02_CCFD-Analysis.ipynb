{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据处理\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import csv\n",
    "import random\n",
    "import math\n",
    "from itertools import product\n",
    "\n",
    "\n",
    "# 网络分析与可视化\n",
    "import networkx as nx\n",
    "from pyvis import network as net\n",
    "import matplotlib.pyplot as plt\n",
    "import powerlaw # Power laws are probability distributions with the form:p(x)∝x−α"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取已经处理好的完整语义网络数据\n",
    "\n",
    "df_complete = pd.read_csv('01_Processed Data/Complete-Data.csv')\n",
    "df_complete.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 搜索出概念对应的所有语义特征及其激活状态，并按照 线索度cue_validity 排序 \n",
    "def List_Semantic_Feature(df, concept):\n",
    "    return df[df['Concept']==concept].sort_values(by=['cue_validity'],ascending=False)[['Feature','cue_validity']]\n",
    "\n",
    "\n",
    "def get_children(df, row_name):\n",
    "    classes = set()\n",
    "    for i, row in df.iterrows():\n",
    "        classes.add(row[row_name])\n",
    "    return classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(List_Semantic_Feature(df_complete,'牛奶')['Feature'])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 生成命名测试用数据 Picture Naming Test Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Input \n",
    "# word_list = ['豆浆', '菠萝汁', '咖啡']\n",
    "word_list = cue_words\n",
    "\n",
    "data = {\n",
    "    'currentStep': 0,\n",
    "    'steps': []\n",
    "}\n",
    "\n",
    "for word in word_list:\n",
    "    new_step = {\n",
    "        'name':word,\n",
    "        # 'image':'local-resource:///Users/zhanghexin/aphasia_viz/src/assets/test_images/'+word+'.jpeg',\n",
    "        'image':'/test_images/'+word+'.jpeg',\n",
    "        'countdown':20,\n",
    "        'result':'fail',\n",
    "        'status':'unchecked',\n",
    "    }\n",
    "    data['steps'].append(new_step)\n",
    "\n",
    "with open(\"test_picture-naming.json\", \"w\") as f: \n",
    "    json.dump(data, f, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Input \n",
    "# word_list = ['豆浆', '菠萝汁', '咖啡']\n",
    "word_list = cue_words\n",
    "\n",
    "\n",
    "data = {\n",
    "    'currentStep': 0,\n",
    "    'steps': [],\n",
    "}\n",
    "\n",
    "for word in word_list:\n",
    "    new_step = {\n",
    "        'name': word,\n",
    "        # 'image':'local-resource:///Users/zhanghexin/aphasia_viz/src/assets/test_images/'+word+'.jpeg',\n",
    "        'image':'/test_images/'+word+'.jpeg',\n",
    "\n",
    "        'countdown':20,\n",
    "        'result':'fail',\n",
    "        'status':'unchecked',\n",
    "        'response':'',\n",
    "        'tab': [],\n",
    "    }\n",
    "\n",
    "    concept = word\n",
    "    rel_list = list(df_complete['Rel'].unique())\n",
    "    \n",
    "    for rel in rel_list:\n",
    "        feature_type = rel+'-'\n",
    "        data_tab = {\n",
    "            'feature_type':feature_type,\n",
    "            'dataSource':[]\n",
    "        }\n",
    "        \n",
    "        feature_list = list(df_complete[(df_complete['Concept']==concept)&(df_complete['Rel']==rel)].sort_values(by=['cue_validity'],ascending=False)['Feature'].unique())[0:10]\n",
    "        for feature in feature_list:\n",
    "            cue_validity = \"%.3f\" % float(df_complete[(df_complete['Concept']==concept)&(df_complete['Feature']==feature)]['cue_validity'])\n",
    "            related_concepts = List_Related_Concepts(concept,feature)[0:5]\n",
    "            confused_feature = List_Confused_Feature(concept,feature)[0:5]\n",
    "            data_row = {\n",
    "                # 'key':feature_list.index(feature),\n",
    "                'key':concept+'/'+feature,\n",
    "                'name':feature,\n",
    "                'cue_validity':cue_validity,\n",
    "                'related_concepts': ', '.join(related_concepts),\n",
    "                'confused_feature': ', '.join(confused_feature).replace(feature_type,''),\n",
    "                'status': 'NO',\n",
    "            }\n",
    "            data_tab['dataSource'].append(data_row)\n",
    "        new_step['tab'].append(data_tab)\n",
    "\n",
    "    data['steps'].append(new_step)\n",
    "\n",
    "with open(\"test_SFA.json\", \"w\") as f: \n",
    "    json.dump(data, f, ensure_ascii=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
